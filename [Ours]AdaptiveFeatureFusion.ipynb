{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7Aeh-I_uxGu",
        "outputId": "0367a57f-1d9b-4b67-d51e-a462a46b81ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "압축 해제 완료!\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "\n",
        "# 압축 파일 경로와 해제 경로 설정\n",
        "zip_path = \"/content/FER.zip\"  # 업로드한 ZIP 파일 이름\n",
        "extract_to = \"/content/FER\"    # 데이터셋을 추출할 폴더 이름\n",
        "\n",
        "# 압축 해제\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "print(\"압축 해제 완료!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import basic packages first\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import pywt\n",
        "\n",
        "# Then import torch and its modules\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "# Import other utilities\n",
        "import gc\n",
        "import traceback\n",
        "from typing import Tuple, List\n",
        "\n",
        "# Check PyTorch installation\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n",
        "\n",
        "# Set random seeds\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "def centralize_gradient(x, gc_axis=0):\n",
        "    \"\"\"Gradient Centralization\"\"\"\n",
        "    size = x.size()\n",
        "    if len(size) > 1:\n",
        "        axis = (gc_axis,) if isinstance(gc_axis, int) else tuple(gc_axis)\n",
        "        mean = x.mean(dim=axis, keepdim=True)\n",
        "        x = x - mean\n",
        "    return x\n",
        "\n",
        "class GC_AdamW(optim.AdamW):\n",
        "    def step(self, closure=None):\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "\n",
        "                # Apply gradient centralization\n",
        "                if len(p.shape) > 1:\n",
        "                    p.grad.data = centralize_gradient(p.grad.data)\n",
        "\n",
        "        return super().step(closure)\n",
        "\n",
        "def mixup_data(x, y, alpha=0.2):\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1\n",
        "\n",
        "    batch_size = x.size()[0]\n",
        "    index = torch.randperm(batch_size).to(x.device)\n",
        "\n",
        "    mixed_x = lam * x + (1 - lam) * x[index]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, y_b, lam\n",
        "\n",
        "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
        "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
        "\n",
        "class WaveletTransform:\n",
        "    def __init__(self, wavelet='db4', level=2):\n",
        "        self.wavelet = wavelet\n",
        "        self.level = level\n",
        "\n",
        "    def apply_transform(self, img):\n",
        "        try:\n",
        "            # Ensure proper dimensions and type\n",
        "            img_array = np.array(img, dtype=np.float32)\n",
        "\n",
        "            # Apply wavelet transform\n",
        "            coeffs = pywt.wavedec2(img_array, self.wavelet, level=self.level)\n",
        "\n",
        "            # Get approximation and detail coefficients\n",
        "            cA, *cD = coeffs\n",
        "\n",
        "            # Initialize feature maps list with normalized approximation coefficients\n",
        "            cA = (cA - np.mean(cA)) / (np.std(cA) + 1e-8)\n",
        "            feature_maps = [cA]\n",
        "\n",
        "            # Get the shape of approximation coefficients\n",
        "            target_shape = cA.shape\n",
        "\n",
        "            # Process detail coefficients\n",
        "            for detail in cD:\n",
        "                if isinstance(detail, tuple):\n",
        "                    for d in detail:\n",
        "                        # Resize detail coefficients to match approximation size\n",
        "                        d_resized = resize_array(d, target_shape)\n",
        "                        d_norm = (d_resized - np.mean(d_resized)) / (np.std(d_resized) + 1e-8)\n",
        "                        feature_maps.append(d_norm)\n",
        "\n",
        "            # Stack and ensure proper shape\n",
        "            stacked = np.stack(feature_maps)\n",
        "            return stacked.astype(np.float32)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in wavelet transform: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "def resize_array(arr, target_shape):\n",
        "    \"\"\"Resize numpy array to target shape using nearest neighbor interpolation\"\"\"\n",
        "    h_ratio = target_shape[0] / arr.shape[0]\n",
        "    w_ratio = target_shape[1] / arr.shape[1]\n",
        "\n",
        "    h_indices = np.floor(np.arange(target_shape[0]) / h_ratio).astype(int)\n",
        "    w_indices = np.floor(np.arange(target_shape[1]) / w_ratio).astype(int)\n",
        "\n",
        "    return arr[h_indices][:, w_indices]\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, csv_file, img_dir, transform=None, train=True):\n",
        "        try:\n",
        "            self.data = pd.read_csv(csv_file)\n",
        "            self.img_dir = img_dir\n",
        "            self.transform = transform\n",
        "            self.train = train\n",
        "            self.wavelet_transform = WaveletTransform()\n",
        "\n",
        "            print(f\"\\nDataset size: {len(self.data)}\")\n",
        "            print(f\"CSV file: {csv_file}\")\n",
        "            print(f\"Image directory: {img_dir}\")\n",
        "\n",
        "            # Print column names for debugging\n",
        "            print(\"\\nCSV columns:\")\n",
        "            print(self.data.columns.tolist())\n",
        "\n",
        "            if train:\n",
        "                print(\"\\nFirst few rows of data:\")\n",
        "                print(self.data.head())\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error initializing dataset: {str(e)}\")\n",
        "            print(\"CSV columns:\", self.data.columns if hasattr(self, 'data') else \"No data loaded\")\n",
        "            raise\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return the size of the dataset\"\"\"\n",
        "        return len(self.data) if hasattr(self, 'data') else 0\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            # Get image filename from first column\n",
        "            img_filename = str(self.data.iloc[idx, 0])\n",
        "            img_path = os.path.join(self.img_dir, img_filename)\n",
        "\n",
        "            # Verify file exists\n",
        "            if not os.path.exists(img_path):\n",
        "                raise FileNotFoundError(f\"Image file not found: {img_path}\")\n",
        "\n",
        "            # Load image\n",
        "            image = Image.open(img_path).convert('L')\n",
        "\n",
        "            # Verify image size\n",
        "            if image.size != (48, 48):\n",
        "                print(f\"Warning: Image {img_path} size is {image.size}, resizing to (48, 48)\")\n",
        "\n",
        "            # Apply transforms\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "\n",
        "            # Get label (sum of emotion scores)\n",
        "            emotion_scores = self.data.iloc[idx, 2:12].astype(float)\n",
        "            label = emotion_scores.argmax()\n",
        "\n",
        "            # Apply wavelet transform\n",
        "            img_np = image.squeeze().numpy()\n",
        "\n",
        "            # Debug information for first image\n",
        "            if idx == 0:\n",
        "                print(f\"\\nDebug - First image:\")\n",
        "                print(f\"Image shape: {img_np.shape}\")\n",
        "                print(f\"Image min/max: {img_np.min():.2f}/{img_np.max():.2f}\")\n",
        "                print(f\"Label: {label}\")\n",
        "                print(f\"Emotion scores: {emotion_scores.tolist()}\")\n",
        "\n",
        "            wavelet_features = self.wavelet_transform.apply_transform(img_np)\n",
        "\n",
        "            if idx == 0:\n",
        "                print(f\"Wavelet features shape: {wavelet_features.shape}\")\n",
        "                print(f\"Wavelet features min/max: {wavelet_features.min():.2f}/{wavelet_features.max():.2f}\")\n",
        "\n",
        "            wavelet_tensor = torch.from_numpy(wavelet_features).float()\n",
        "\n",
        "            return wavelet_tensor, label\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image {idx}: {str(e)}\")\n",
        "            print(f\"Image path: {img_path}\")\n",
        "            print(f\"Data row {idx}:\", self.data.iloc[idx].tolist())\n",
        "            raise\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(SelfAttention, self).__init__()\n",
        "        self.query = nn.Conv2d(in_channels, in_channels//8, 1)\n",
        "        self.key = nn.Conv2d(in_channels, in_channels//8, 1)\n",
        "        self.value = nn.Conv2d(in_channels, in_channels, 1)\n",
        "        self.gamma = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, C, H, W = x.size()\n",
        "\n",
        "        q = self.query(x).view(batch_size, -1, H*W).permute(0, 2, 1)\n",
        "        k = self.key(x).view(batch_size, -1, H*W)\n",
        "        v = self.value(x).view(batch_size, -1, H*W)\n",
        "\n",
        "        attention = torch.bmm(q, k)\n",
        "        attention = F.softmax(attention, dim=2)\n",
        "\n",
        "        out = torch.bmm(v, attention.permute(0, 2, 1))\n",
        "        out = out.view(batch_size, C, H, W)\n",
        "\n",
        "        return self.gamma * out + x\n",
        "\n",
        "class KTN(nn.Module):\n",
        "    def __init__(self, num_classes=10, input_channels=7):\n",
        "        super(KTN, self).__init__()\n",
        "\n",
        "        print(f\"\\nInitializing KTN with:\")\n",
        "        print(f\"Number of classes: {num_classes}\")\n",
        "        print(f\"Input channels: {input_channels}\")\n",
        "\n",
        "        # Increased initial channels and added dropout\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(input_channels, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(0.2),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(0.3),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(0.4),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        # Added residual connections and more attention layers\n",
        "        self.transfer = nn.Sequential(\n",
        "            nn.Conv2d(512, 768, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(768),\n",
        "            nn.ReLU(inplace=True),\n",
        "            SelfAttention(768),\n",
        "            nn.Dropout2d(0.4),\n",
        "\n",
        "            nn.Conv2d(768, 768, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(768),\n",
        "            nn.ReLU(inplace=True),\n",
        "            SelfAttention(768),\n",
        "            nn.Dropout2d(0.4)\n",
        "        )\n",
        "\n",
        "        # Added more layers in classifier with dropout\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(768, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.transfer(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "def setup_cuda():\n",
        "    try:\n",
        "        if torch.cuda.is_available():\n",
        "            device = torch.device(\"cuda\")\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "            # Reset device\n",
        "            torch.cuda.reset_peak_memory_stats()\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "            # Set device properties\n",
        "            cudnn.benchmark = True\n",
        "            cudnn.deterministic = True\n",
        "\n",
        "            print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
        "            print(f\"Memory allocated: {torch.cuda.memory_allocated(0)/(1024*1024):.2f} MB\")\n",
        "        else:\n",
        "            device = torch.device(\"cpu\")\n",
        "            print(\"CUDA not available, using CPU\")\n",
        "    except Exception as e:\n",
        "        print(f\"CUDA initialization failed: {str(e)}\")\n",
        "        device = torch.device(\"cpu\")\n",
        "        print(\"Falling back to CPU\")\n",
        "    return device\n",
        "\n",
        "def train_model(model, train_loader, criterion, optimizer, device, epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "        try:\n",
        "            images = images.float().to(device)\n",
        "            labels = labels.long().to(device)\n",
        "\n",
        "            # Apply mixup\n",
        "            images, labels_a, labels_b, lam = mixup_data(images, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "\n",
        "            # Use mixup loss\n",
        "            loss = mixup_criterion(criterion, outputs, labels_a, labels_b, lam)\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            # Calculate accuracy with original labels\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += (lam * predicted.eq(labels_a).float() +\n",
        "                       (1 - lam) * predicted.eq(labels_b).float()).sum().item()\n",
        "\n",
        "            if batch_idx % 100 == 0:\n",
        "                print(f'Epoch: {epoch+1}, Batch: {batch_idx}, '\n",
        "                      f'Loss: {running_loss/(batch_idx+1):.4f}, '\n",
        "                      f'Acc: {100.*correct/total:.2f}%')\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in batch {batch_idx}: {str(e)}\")\n",
        "            print(\"Traceback:\")\n",
        "            traceback.print_exc()\n",
        "            continue\n",
        "\n",
        "    return 100. * correct / total\n",
        "\n",
        "def validate_model(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            try:\n",
        "                # Ensure data types are correct\n",
        "                images = images.float()\n",
        "                labels = labels.long()\n",
        "\n",
        "                # Move to device\n",
        "                images = images.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # Statistics\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += labels.size(0)\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error in validation: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "    avg_loss = val_loss / len(val_loader)\n",
        "    accuracy = 100. * correct / total\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "def verify_submission(submission_path):\n",
        "    \"\"\"\n",
        "    Verify the submission file format\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(submission_path)\n",
        "\n",
        "        # Check columns\n",
        "        expected_columns = ['ID', 'Prediction']\n",
        "        if not all(col in df.columns for col in expected_columns):\n",
        "            print(\"Error: Missing required columns\")\n",
        "            return False\n",
        "\n",
        "        # Check ID range (now starting from 0)\n",
        "        if df['ID'].min() != 0 or df['ID'].max() != len(df) - 1:\n",
        "            print(\"Warning: ID range might be incorrect\")\n",
        "            print(f\"Expected range: 0 to {len(df) - 1}\")\n",
        "            print(f\"Actual range: {df['ID'].min()} to {df['ID'].max()}\")\n",
        "\n",
        "        # Check predictions range\n",
        "        if df['Prediction'].min() < 0 or df['Prediction'].max() >= 10:\n",
        "            print(\"Error: Predictions out of valid range (0-9)\")\n",
        "            return False\n",
        "\n",
        "        print(\"\\nSubmission file verification:\")\n",
        "        print(f\"Number of predictions: {len(df)}\")\n",
        "        print(f\"ID range: {df['ID'].min()} to {df['ID'].max()}\")\n",
        "        print(f\"Prediction range: {df['Prediction'].min()} to {df['Prediction'].max()}\")\n",
        "        print(\"\\nPrediction distribution:\")\n",
        "        print(df['Prediction'].value_counts().sort_index())\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error verifying submission: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "def test_model(model, test_dir, submission_path, device):\n",
        "    \"\"\"\n",
        "    Test the model and create submission file\n",
        "    \"\"\"\n",
        "    try:\n",
        "        model.eval()\n",
        "\n",
        "        # Create transforms for test images\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize((48, 48)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485], std=[0.229])\n",
        "        ])\n",
        "\n",
        "        wavelet_transform = WaveletTransform()\n",
        "\n",
        "        # Create submission dataframe\n",
        "        results = {'ID': [], 'Prediction': []}\n",
        "\n",
        "        # Process each image in test directory\n",
        "        test_files = sorted(os.listdir(test_dir))\n",
        "\n",
        "        print(\"\\nStarting test prediction...\")\n",
        "        print(f\"Found {len(test_files)} test images\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for idx, img_name in enumerate(test_files):  # Start index from 0\n",
        "                try:\n",
        "                    # Use index as ID\n",
        "                    img_path = os.path.join(test_dir, img_name)\n",
        "\n",
        "                    # Load and process image\n",
        "                    image = Image.open(img_path).convert('L')\n",
        "\n",
        "                    # Apply transforms\n",
        "                    image = transform(image)\n",
        "\n",
        "                    # Apply wavelet transform\n",
        "                    img_np = image.squeeze().numpy()\n",
        "                    wavelet_features = wavelet_transform.apply_transform(img_np)\n",
        "                    wavelet_tensor = torch.from_numpy(wavelet_features).float()\n",
        "\n",
        "                    # Add batch dimension\n",
        "                    wavelet_tensor = wavelet_tensor.unsqueeze(0).to(device)\n",
        "\n",
        "                    # Get prediction\n",
        "                    outputs = model(wavelet_tensor)\n",
        "                    _, predicted = outputs.max(1)\n",
        "\n",
        "                    # Store results using index as ID (starting from 0)\n",
        "                    results['ID'].append(idx)\n",
        "                    results['Prediction'].append(predicted.item())\n",
        "\n",
        "                    if (idx + 1) % 100 == 0:\n",
        "                        print(f\"Processed {idx + 1}/{len(test_files)} images\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing image {img_name}: {str(e)}\")\n",
        "                    print(f\"Image path: {img_path}\")\n",
        "                    continue\n",
        "\n",
        "        # Create and save submission file\n",
        "        submission_df = pd.DataFrame(results)\n",
        "        submission_df = submission_df.sort_values('ID')  # Sort by ID\n",
        "        submission_df.to_csv(submission_path, index=False)\n",
        "        print(f\"\\nSubmission file created at: {submission_path}\")\n",
        "        print(f\"Total predictions: {len(submission_df)}\")\n",
        "        print(\"\\nPrediction distribution:\")\n",
        "        print(submission_df['Prediction'].value_counts())\n",
        "\n",
        "        # Verify submission file\n",
        "        print(\"\\nVerifying submission file...\")\n",
        "        if verify_submission(submission_path):\n",
        "            print(\"Submission file verified successfully\")\n",
        "        else:\n",
        "            print(\"Submission file verification failed\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in test_model: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        # Set CUDA environment variables\n",
        "        os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "        os.environ['TORCH_USE_CUDA_DSA'] = '1'\n",
        "\n",
        "        device = setup_cuda()\n",
        "\n",
        "        # Data transforms with augmentation\n",
        "        transform_train = transforms.Compose([\n",
        "            transforms.Resize((48, 48)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomRotation(10),\n",
        "            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
        "            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485], std=[0.229])\n",
        "        ])\n",
        "\n",
        "        transform_test = transforms.Compose([\n",
        "            transforms.Resize((48, 48)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485], std=[0.229])\n",
        "        ])\n",
        "\n",
        "        # Create datasets with different transforms\n",
        "        print(\"\\nInitializing datasets...\")\n",
        "        train_dataset = CustomDataset(\n",
        "            csv_file='/content/FER/fer-competition/train_label.csv',\n",
        "            img_dir='/content/FER/fer-competition/FER2013Train',\n",
        "            transform=transform_train,\n",
        "            train=True\n",
        "        )\n",
        "\n",
        "        val_dataset = CustomDataset(\n",
        "            csv_file='/content/FER/fer-competition/valid_label.csv',\n",
        "            img_dir='/content/FER/fer-competition/FER2013Valid',\n",
        "            transform=transform_test,\n",
        "            train=True\n",
        "        )\n",
        "\n",
        "        # Create data loaders with smaller batch size\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=32,\n",
        "            shuffle=True,\n",
        "            num_workers=2,\n",
        "            pin_memory=True if device.type == 'cuda' else False\n",
        "        )\n",
        "\n",
        "        val_loader = DataLoader(\n",
        "            val_dataset,\n",
        "            batch_size=32,\n",
        "            shuffle=False,\n",
        "            num_workers=2,\n",
        "            pin_memory=True if device.type == 'cuda' else False\n",
        "        )\n",
        "\n",
        "        # Initialize model\n",
        "        print(\"\\nInitializing model...\")\n",
        "        model = KTN(num_classes=10, input_channels=7)\n",
        "        model = model.to(device)\n",
        "\n",
        "        # Print model summary\n",
        "        print(\"\\nModel structure:\")\n",
        "        print(model)\n",
        "        print(f\"\\nModel device: {next(model.parameters()).device}\")\n",
        "\n",
        "        # Training mode\n",
        "        if not os.path.exists('best_ktn_model.pth'):\n",
        "            criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "\n",
        "            # Use AdamW with weight decay\n",
        "            optimizer = GC_AdamW(\n",
        "                model.parameters(),\n",
        "                lr=0.001,\n",
        "                weight_decay=0.01,\n",
        "                betas=(0.9, 0.999)\n",
        "            )\n",
        "\n",
        "            # Cosine annealing scheduler with warm restarts\n",
        "            scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "                optimizer,\n",
        "                T_0=10,\n",
        "                T_mult=2,\n",
        "                eta_min=1e-6\n",
        "            )\n",
        "\n",
        "            # Early stopping\n",
        "            patience = 10\n",
        "            best_accuracy = 0.0\n",
        "            no_improve_epochs = 0\n",
        "            epochs = 20\n",
        "\n",
        "            print(\"\\nStarting training...\")\n",
        "            for epoch in range(epochs):\n",
        "                # Training\n",
        "                train_accuracy = train_model(model, train_loader, criterion, optimizer, device, epoch)\n",
        "\n",
        "                # Validation\n",
        "                val_loss, val_accuracy = validate_model(model, val_loader, criterion, device)\n",
        "\n",
        "                # Learning rate scheduling\n",
        "                scheduler.step()\n",
        "\n",
        "                print(f'\\nEpoch {epoch+1}/{epochs}:')\n",
        "                print(f'Training Accuracy: {train_accuracy:.2f}%')\n",
        "                print(f'Validation Loss: {val_loss:.4f}')\n",
        "                print(f'Validation Accuracy: {val_accuracy:.2f}%')\n",
        "                print(f'Learning Rate: {scheduler.get_last_lr()[0]:.6f}')\n",
        "\n",
        "                # Save best model and check for early stopping\n",
        "                if val_accuracy > best_accuracy:\n",
        "                    best_accuracy = val_accuracy\n",
        "                    torch.save(model.state_dict(), 'best_ktn_model.pth')\n",
        "                    print(f'New best model saved with accuracy: {best_accuracy:.2f}%')\n",
        "                    no_improve_epochs = 0\n",
        "                else:\n",
        "                    no_improve_epochs += 1\n",
        "                    if no_improve_epochs >= patience:\n",
        "                        print(f'\\nEarly stopping after {patience} epochs without improvement')\n",
        "                        break\n",
        "\n",
        "                # Memory cleanup\n",
        "                torch.cuda.empty_cache()\n",
        "                gc.collect()\n",
        "\n",
        "        # Testing mode\n",
        "        print(\"\\nLoading best model for testing...\")\n",
        "        try:\n",
        "            # Initialize model\n",
        "            model = KTN(num_classes=10, input_channels=7)\n",
        "\n",
        "            # Load the state dict\n",
        "            model.load_state_dict(torch.load('best_ktn_model.pth', map_location='cpu'))\n",
        "\n",
        "            # Move model to device after loading\n",
        "            model = model.to(device)\n",
        "            print(\"Model loaded successfully\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model: {str(e)}\")\n",
        "            traceback.print_exc()\n",
        "            return\n",
        "\n",
        "        # Set model to evaluation mode\n",
        "        model.eval()\n",
        "\n",
        "        # Run testing and create submission file\n",
        "        test_model(\n",
        "            model=model,\n",
        "            test_dir='/content/FER/fer-competition/FER2013Test',\n",
        "            submission_path='/content/FER/fer-competition/submission.csv',\n",
        "            device=device\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in main: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "        return\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    try:\n",
        "        main()\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nProcess interrupted by user\")\n",
        "    except Exception as e:\n",
        "        print(f\"Fatal error: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "    finally:\n",
        "        print(\"\\nProgram finished\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AxG4LJJKkwA",
        "outputId": "62a952a7-a93e-41c0-991d-29a61c5aee96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.5.1+cu124\n",
            "CUDA available: True\n",
            "CUDA version: 12.4\n",
            "Using GPU: Tesla T4\n",
            "Memory allocated: 16.25 MB\n",
            "\n",
            "Initializing datasets...\n",
            "\n",
            "Dataset size: 28557\n",
            "CSV file: /content/FER/fer-competition/train_label.csv\n",
            "Image directory: /content/FER/fer-competition/FER2013Train\n",
            "\n",
            "CSV columns:\n",
            "['fer0000000.png', '(0, 0, 48, 48)', '4', '0', '0.1', '1', '3', '2', '0.2', '0.3', '0.4', '0.5']\n",
            "\n",
            "First few rows of data:\n",
            "   fer0000000.png  (0, 0, 48, 48)  4  0  0.1  1  3  2  0.2  0.3  0.4  0.5\n",
            "0  fer0000001.png  (0, 0, 48, 48)  6  0    1  1  0  0    0    0    2    0\n",
            "1  fer0000002.png  (0, 0, 48, 48)  5  0    0  3  1  0    0    0    1    0\n",
            "2  fer0000003.png  (0, 0, 48, 48)  4  0    0  4  1  0    0    0    1    0\n",
            "3  fer0000004.png  (0, 0, 48, 48)  9  0    0  1  0  0    0    0    0    0\n",
            "4  fer0000005.png  (0, 0, 48, 48)  6  0    0  1  0  0    1    1    1    0\n",
            "\n",
            "Dataset size: 3578\n",
            "CSV file: /content/FER/fer-competition/valid_label.csv\n",
            "Image directory: /content/FER/fer-competition/FER2013Valid\n",
            "\n",
            "CSV columns:\n",
            "['fer0028638.png', '(0, 0, 48, 48)', '4', '0', '0.1', '0.2', '1', '0.3', '0.4', '4.1', '1.1', '0.5']\n",
            "\n",
            "First few rows of data:\n",
            "   fer0028638.png  (0, 0, 48, 48)  4   0  0.1  0.2  1  0.3  0.4  4.1  1.1  0.5\n",
            "0  fer0028639.png  (0, 0, 48, 48)  1   0    0    1  0    2    0    6    0    0\n",
            "1  fer0028640.png  (0, 0, 48, 48)  7   0    0    0  2    0    0    1    0    0\n",
            "2  fer0028641.png  (0, 0, 48, 48)  5   5    0    0  0    0    0    0    0    0\n",
            "3  fer0028642.png  (0, 0, 48, 48)  0  10    0    0  0    0    0    0    0    0\n",
            "4  fer0028643.png  (0, 0, 48, 48)  0  10    0    0  0    0    0    0    0    0\n",
            "\n",
            "Initializing model...\n",
            "\n",
            "Initializing KTN with:\n",
            "Number of classes: 10\n",
            "Input channels: 7\n",
            "\n",
            "Model structure:\n",
            "KTN(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(7, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout2d(p=0.2, inplace=False)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Dropout2d(p=0.3, inplace=False)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): Dropout2d(p=0.4, inplace=False)\n",
            "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (transfer): Sequential(\n",
            "    (0): Conv2d(512, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): SelfAttention(\n",
            "      (query): Conv2d(768, 96, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (key): Conv2d(768, 96, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (value): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (4): Dropout2d(p=0.4, inplace=False)\n",
            "    (5): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): SelfAttention(\n",
            "      (query): Conv2d(768, 96, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (key): Conv2d(768, 96, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (value): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (9): Dropout2d(p=0.4, inplace=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (1): Flatten(start_dim=1, end_dim=-1)\n",
            "    (2): Linear(in_features=768, out_features=512, bias=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Dropout(p=0.5, inplace=False)\n",
            "    (5): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Dropout(p=0.5, inplace=False)\n",
            "    (8): Linear(in_features=256, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "Model device: cuda:0\n",
            "\n",
            "Starting training...\n",
            "Epoch: 1, Batch: 0, Loss: 2.3001, Acc: 21.93%\n",
            "Epoch: 1, Batch: 100, Loss: 1.8474, Acc: 33.50%\n",
            "\n",
            "Debug - First image:\n",
            "Image shape: (48, 48)\n",
            "Image min/max: -2.07/1.77\n",
            "Label: 0\n",
            "Emotion scores: [6.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0]\n",
            "Wavelet features shape: (7, 17, 17)\n",
            "Wavelet features min/max: -3.96/6.77\n",
            "Epoch: 1, Batch: 200, Loss: 1.8418, Acc: 32.97%\n",
            "Epoch: 1, Batch: 300, Loss: 1.8350, Acc: 33.11%\n",
            "Epoch: 1, Batch: 400, Loss: 1.8314, Acc: 33.26%\n",
            "Epoch: 1, Batch: 500, Loss: 1.8305, Acc: 33.51%\n",
            "Epoch: 1, Batch: 600, Loss: 1.8327, Acc: 33.43%\n",
            "Epoch: 1, Batch: 700, Loss: 1.8284, Acc: 33.60%\n",
            "Epoch: 1, Batch: 800, Loss: 1.8247, Acc: 33.97%\n",
            "\n",
            "Debug - First image:\n",
            "Image shape: (48, 48)\n",
            "Image min/max: -2.12/2.13\n",
            "Label: 7\n",
            "Emotion scores: [1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 6.0, 0.0, 0.0]\n",
            "Wavelet features shape: (7, 17, 17)\n",
            "Wavelet features min/max: -6.84/6.96\n",
            "\n",
            "Epoch 1/20:\n",
            "Training Accuracy: 34.14%\n",
            "Validation Loss: 1.7690\n",
            "Validation Accuracy: 37.34%\n",
            "Learning Rate: 0.000976\n",
            "New best model saved with accuracy: 37.34%\n",
            "Epoch: 2, Batch: 0, Loss: 1.7250, Acc: 36.77%\n",
            "\n",
            "Debug - First image:\n",
            "Image shape: (48, 48)\n",
            "Image min/max: -2.12/1.02\n",
            "Label: 0\n",
            "Emotion scores: [6.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0]\n",
            "Wavelet features shape: (7, 17, 17)\n",
            "Wavelet features min/max: -4.96/5.37\n",
            "Epoch: 2, Batch: 100, Loss: 1.8036, Acc: 35.13%\n",
            "Epoch: 2, Batch: 200, Loss: 1.8094, Acc: 34.91%\n",
            "Epoch: 2, Batch: 300, Loss: 1.8065, Acc: 35.15%\n",
            "Epoch: 2, Batch: 400, Loss: 1.8044, Acc: 34.88%\n",
            "Epoch: 2, Batch: 500, Loss: 1.7975, Acc: 35.66%\n",
            "Epoch: 2, Batch: 600, Loss: 1.7938, Acc: 35.93%\n",
            "Epoch: 2, Batch: 700, Loss: 1.7917, Acc: 35.86%\n",
            "Epoch: 2, Batch: 800, Loss: 1.7890, Acc: 36.19%\n",
            "\n",
            "Debug - First image:\n",
            "Image shape: (48, 48)\n",
            "Image min/max: -2.12/2.13\n",
            "Label: 7\n",
            "Emotion scores: [1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 6.0, 0.0, 0.0]\n",
            "Wavelet features shape: (7, 17, 17)\n",
            "Wavelet features min/max: -6.84/6.96\n",
            "\n",
            "Epoch 2/20:\n",
            "Training Accuracy: 36.40%\n",
            "Validation Loss: 1.7317\n",
            "Validation Accuracy: 39.32%\n",
            "Learning Rate: 0.000905\n",
            "New best model saved with accuracy: 39.32%\n",
            "Epoch: 3, Batch: 0, Loss: 1.7015, Acc: 30.98%\n",
            "Epoch: 3, Batch: 100, Loss: 1.7615, Acc: 38.01%\n",
            "Epoch: 3, Batch: 200, Loss: 1.7677, Acc: 37.79%\n",
            "Epoch: 3, Batch: 300, Loss: 1.7664, Acc: 37.73%\n",
            "\n",
            "Debug - First image:\n",
            "Image shape: (48, 48)\n",
            "Image min/max: -2.12/2.25\n",
            "Label: 0\n",
            "Emotion scores: [6.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0]\n",
            "Wavelet features shape: (7, 17, 17)\n",
            "Wavelet features min/max: -4.88/5.21\n",
            "Epoch: 3, Batch: 400, Loss: 1.7641, Acc: 37.89%\n",
            "Epoch: 3, Batch: 500, Loss: 1.7602, Acc: 38.09%\n",
            "Epoch: 3, Batch: 600, Loss: 1.7608, Acc: 38.14%\n",
            "Epoch: 3, Batch: 700, Loss: 1.7561, Acc: 38.42%\n",
            "Epoch: 3, Batch: 800, Loss: 1.7539, Acc: 38.56%\n",
            "\n",
            "Debug - First image:\n",
            "Image shape: (48, 48)\n",
            "Image min/max: -2.12/2.13\n",
            "Label: 7\n",
            "Emotion scores: [1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 6.0, 0.0, 0.0]\n",
            "Wavelet features shape: (7, 17, 17)\n",
            "Wavelet features min/max: -6.84/6.96\n",
            "\n",
            "Epoch 3/20:\n",
            "Training Accuracy: 38.66%\n",
            "Validation Loss: 1.7060\n",
            "Validation Accuracy: 42.71%\n",
            "Learning Rate: 0.000794\n",
            "New best model saved with accuracy: 42.71%\n",
            "Epoch: 4, Batch: 0, Loss: 1.7744, Acc: 43.75%\n",
            "Epoch: 4, Batch: 100, Loss: 1.7426, Acc: 40.83%\n",
            "Epoch: 4, Batch: 200, Loss: 1.7286, Acc: 41.79%\n",
            "Epoch: 4, Batch: 300, Loss: 1.7259, Acc: 41.91%\n",
            "Epoch: 4, Batch: 400, Loss: 1.7250, Acc: 42.14%\n",
            "Epoch: 4, Batch: 500, Loss: 1.7236, Acc: 42.52%\n",
            "Epoch: 4, Batch: 600, Loss: 1.7198, Acc: 42.62%\n",
            "Epoch: 4, Batch: 700, Loss: 1.7178, Acc: 42.70%\n",
            "Epoch: 4, Batch: 800, Loss: 1.7133, Acc: 42.91%\n",
            "\n",
            "Debug - First image:\n",
            "Image shape: (48, 48)\n",
            "Image min/max: -2.12/1.46\n",
            "Label: 0\n",
            "Emotion scores: [6.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0]\n",
            "Wavelet features shape: (7, 17, 17)\n",
            "Wavelet features min/max: -5.51/4.94\n",
            "\n",
            "Debug - First image:\n",
            "Image shape: (48, 48)\n",
            "Image min/max: -2.12/2.13\n",
            "Label: 7\n",
            "Emotion scores: [1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 6.0, 0.0, 0.0]\n",
            "Wavelet features shape: (7, 17, 17)\n",
            "Wavelet features min/max: -6.84/6.96\n",
            "\n",
            "Epoch 4/20:\n",
            "Training Accuracy: 43.04%\n",
            "Validation Loss: 1.6249\n",
            "Validation Accuracy: 49.75%\n",
            "Learning Rate: 0.000655\n",
            "New best model saved with accuracy: 49.75%\n",
            "Epoch: 5, Batch: 0, Loss: 1.7177, Acc: 46.45%\n",
            "Epoch: 5, Batch: 100, Loss: 1.6887, Acc: 44.57%\n",
            "Epoch: 5, Batch: 200, Loss: 1.6894, Acc: 44.77%\n",
            "Epoch: 5, Batch: 300, Loss: 1.6851, Acc: 45.16%\n",
            "Epoch: 5, Batch: 400, Loss: 1.6844, Acc: 45.57%\n",
            "Epoch: 5, Batch: 500, Loss: 1.6801, Acc: 45.73%\n",
            "Epoch: 5, Batch: 600, Loss: 1.6773, Acc: 45.86%\n",
            "Epoch: 5, Batch: 700, Loss: 1.6758, Acc: 45.95%\n",
            "\n",
            "Debug - First image:\n",
            "Image shape: (48, 48)\n",
            "Image min/max: -1.96/0.78\n",
            "Label: 0\n",
            "Emotion scores: [6.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0]\n",
            "Wavelet features shape: (7, 17, 17)\n",
            "Wavelet features min/max: -5.46/6.35\n",
            "Epoch: 5, Batch: 800, Loss: 1.6753, Acc: 46.18%\n",
            "\n",
            "Debug - First image:\n",
            "Image shape: (48, 48)\n",
            "Image min/max: -2.12/2.13\n",
            "Label: 7\n",
            "Emotion scores: [1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 6.0, 0.0, 0.0]\n",
            "Wavelet features shape: (7, 17, 17)\n",
            "Wavelet features min/max: -6.84/6.96\n",
            "\n",
            "Epoch 5/20:\n",
            "Training Accuracy: 46.42%\n",
            "Validation Loss: 1.5581\n",
            "Validation Accuracy: 53.94%\n",
            "Learning Rate: 0.000501\n",
            "New best model saved with accuracy: 53.94%\n",
            "Epoch: 6, Batch: 0, Loss: 1.4987, Acc: 62.49%\n",
            "Epoch: 6, Batch: 100, Loss: 1.6278, Acc: 49.62%\n",
            "Epoch: 6, Batch: 200, Loss: 1.6608, Acc: 47.80%\n",
            "Epoch: 6, Batch: 300, Loss: 1.6500, Acc: 48.20%\n",
            "\n",
            "Debug - First image:\n",
            "Image shape: (48, 48)\n",
            "Image min/max: -1.96/1.84\n",
            "Label: 0\n",
            "Emotion scores: [6.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0]\n",
            "Wavelet features shape: (7, 17, 17)\n",
            "Wavelet features min/max: -5.27/6.23\n",
            "Epoch: 6, Batch: 400, Loss: 1.6491, Acc: 48.13%\n",
            "Epoch: 6, Batch: 500, Loss: 1.6469, Acc: 48.32%\n",
            "Epoch: 6, Batch: 600, Loss: 1.6464, Acc: 48.48%\n",
            "Epoch: 6, Batch: 700, Loss: 1.6478, Acc: 48.38%\n",
            "Epoch: 6, Batch: 800, Loss: 1.6438, Acc: 48.60%\n",
            "\n",
            "Debug - First image:\n",
            "Image shape: (48, 48)\n",
            "Image min/max: -2.12/2.13\n",
            "Label: 7\n",
            "Emotion scores: [1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 6.0, 0.0, 0.0]\n",
            "Wavelet features shape: (7, 17, 17)\n",
            "Wavelet features min/max: -6.84/6.96\n",
            "\n",
            "Epoch 6/20:\n",
            "Training Accuracy: 48.78%\n",
            "Validation Loss: 1.5760\n",
            "Validation Accuracy: 50.78%\n",
            "Learning Rate: 0.000346\n",
            "Epoch: 7, Batch: 0, Loss: 1.4544, Acc: 61.71%\n",
            "Epoch: 7, Batch: 100, Loss: 1.5916, Acc: 51.52%\n",
            "Epoch: 7, Batch: 200, Loss: 1.6133, Acc: 50.54%\n",
            "Epoch: 7, Batch: 300, Loss: 1.6205, Acc: 50.06%\n",
            "Epoch: 7, Batch: 400, Loss: 1.6277, Acc: 49.73%\n",
            "Epoch: 7, Batch: 500, Loss: 1.6229, Acc: 50.02%\n",
            "Epoch: 7, Batch: 600, Loss: 1.6206, Acc: 50.03%\n",
            "\n",
            "Debug - First image:\n",
            "Image shape: (48, 48)\n",
            "Image min/max: -2.12/1.86\n",
            "Label: 0\n",
            "Emotion scores: [6.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0]\n",
            "Wavelet features shape: (7, 17, 17)\n",
            "Wavelet features min/max: -6.24/5.65\n",
            "Epoch: 7, Batch: 700, Loss: 1.6239, Acc: 49.80%\n",
            "Epoch: 7, Batch: 800, Loss: 1.6218, Acc: 49.98%\n",
            "\n",
            "Debug - First image:\n",
            "Image shape: (48, 48)\n",
            "Image min/max: -2.12/2.13\n",
            "Label: 7\n",
            "Emotion scores: [1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 6.0, 0.0, 0.0]\n",
            "Wavelet features shape: (7, 17, 17)\n",
            "Wavelet features min/max: -6.84/6.96\n",
            "\n",
            "Epoch 7/20:\n",
            "Training Accuracy: 49.97%\n",
            "Validation Loss: 1.5120\n",
            "Validation Accuracy: 56.37%\n",
            "Learning Rate: 0.000207\n",
            "New best model saved with accuracy: 56.37%\n",
            "Epoch: 8, Batch: 0, Loss: 1.6594, Acc: 49.18%\n",
            "Epoch: 8, Batch: 100, Loss: 1.6111, Acc: 50.74%\n",
            "Epoch: 8, Batch: 200, Loss: 1.6081, Acc: 51.04%\n",
            "Epoch: 8, Batch: 300, Loss: 1.6116, Acc: 50.86%\n",
            "Epoch: 8, Batch: 400, Loss: 1.6129, Acc: 50.66%\n",
            "\n",
            "Debug - First image:\n",
            "Image shape: (48, 48)\n",
            "Image min/max: -2.12/1.53\n",
            "Label: 0\n",
            "Emotion scores: [6.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0]\n",
            "Wavelet features shape: (7, 17, 17)\n",
            "Wavelet features min/max: -4.90/5.74\n",
            "Epoch: 8, Batch: 500, Loss: 1.6085, Acc: 50.99%\n",
            "Epoch: 8, Batch: 600, Loss: 1.6085, Acc: 50.95%\n",
            "Epoch: 8, Batch: 700, Loss: 1.6054, Acc: 51.10%\n",
            "Epoch: 8, Batch: 800, Loss: 1.6076, Acc: 50.97%\n",
            "\n",
            "Debug - First image:\n",
            "Image shape: (48, 48)\n",
            "Image min/max: -2.12/2.13\n",
            "Label: 7\n",
            "Emotion scores: [1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 6.0, 0.0, 0.0]\n",
            "Wavelet features shape: (7, 17, 17)\n",
            "Wavelet features min/max: -6.84/6.96\n",
            "\n",
            "Epoch 8/20:\n",
            "Training Accuracy: 51.00%\n",
            "Validation Loss: 1.5157\n",
            "Validation Accuracy: 55.62%\n",
            "Learning Rate: 0.000096\n",
            "Epoch: 9, Batch: 0, Loss: 1.7133, Acc: 50.27%\n",
            "\n",
            "Debug - First image:\n",
            "Image shape: (48, 48)\n",
            "Image min/max: -2.12/2.25\n",
            "Label: 0\n",
            "Emotion scores: [6.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0]\n",
            "Wavelet features shape: (7, 17, 17)\n",
            "Wavelet features min/max: -6.27/5.06\n",
            "Epoch: 9, Batch: 100, Loss: 1.6206, Acc: 49.72%\n",
            "Epoch: 9, Batch: 200, Loss: 1.6163, Acc: 50.11%\n",
            "Epoch: 9, Batch: 300, Loss: 1.6104, Acc: 50.55%\n",
            "Epoch: 9, Batch: 400, Loss: 1.6053, Acc: 50.58%\n",
            "Epoch: 9, Batch: 500, Loss: 1.6037, Acc: 50.71%\n",
            "Epoch: 9, Batch: 600, Loss: 1.6008, Acc: 51.02%\n",
            "Epoch: 9, Batch: 700, Loss: 1.5990, Acc: 51.20%\n",
            "Epoch: 9, Batch: 800, Loss: 1.5956, Acc: 51.35%\n",
            "\n",
            "Debug - First image:\n",
            "Image shape: (48, 48)\n",
            "Image min/max: -2.12/2.13\n",
            "Label: 7\n",
            "Emotion scores: [1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 6.0, 0.0, 0.0]\n",
            "Wavelet features shape: (7, 17, 17)\n",
            "Wavelet features min/max: -6.84/6.96\n",
            "\n",
            "Epoch 9/20:\n",
            "Training Accuracy: 51.35%\n",
            "Validation Loss: 1.5003\n",
            "Validation Accuracy: 56.46%\n",
            "Learning Rate: 0.000025\n",
            "New best model saved with accuracy: 56.46%\n",
            "Epoch: 10, Batch: 0, Loss: 1.7568, Acc: 34.38%\n",
            "Epoch: 10, Batch: 100, Loss: 1.6120, Acc: 50.87%\n",
            "Epoch: 10, Batch: 200, Loss: 1.6157, Acc: 50.68%\n",
            "Epoch: 10, Batch: 300, Loss: 1.6075, Acc: 51.03%\n",
            "Epoch: 10, Batch: 400, Loss: 1.6036, Acc: 50.92%\n",
            "\n",
            "Debug - First image:\n",
            "Image shape: (48, 48)\n",
            "Image min/max: -2.12/2.25\n",
            "Label: 0\n",
            "Emotion scores: [6.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0]\n",
            "Wavelet features shape: (7, 17, 17)\n",
            "Wavelet features min/max: -4.80/4.73\n",
            "Epoch: 10, Batch: 500, Loss: 1.6031, Acc: 50.92%\n",
            "Epoch: 10, Batch: 600, Loss: 1.6023, Acc: 51.03%\n",
            "Epoch: 10, Batch: 700, Loss: 1.5993, Acc: 51.26%\n",
            "Epoch: 10, Batch: 800, Loss: 1.5975, Acc: 51.35%\n",
            "\n",
            "Debug - First image:\n",
            "Image shape: (48, 48)\n",
            "Image min/max: -2.12/2.13\n",
            "Label: 7\n",
            "Emotion scores: [1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 6.0, 0.0, 0.0]\n",
            "Wavelet features shape: (7, 17, 17)\n",
            "Wavelet features min/max: -6.84/6.96\n",
            "\n",
            "Epoch 10/20:\n",
            "Training Accuracy: 51.16%\n",
            "Validation Loss: 1.5030\n",
            "Validation Accuracy: 56.34%\n",
            "Learning Rate: 0.001000\n",
            "Epoch: 11, Batch: 0, Loss: 1.6807, Acc: 45.54%\n",
            "Epoch: 11, Batch: 100, Loss: 1.6235, Acc: 50.66%\n",
            "Epoch: 11, Batch: 200, Loss: 1.6123, Acc: 50.95%\n",
            "Epoch: 11, Batch: 300, Loss: 1.6165, Acc: 50.40%\n",
            "Epoch: 11, Batch: 400, Loss: 1.6171, Acc: 50.35%\n",
            "Epoch: 11, Batch: 500, Loss: 1.6195, Acc: 50.30%\n",
            "\n",
            "Debug - First image:\n",
            "Image shape: (48, 48)\n",
            "Image min/max: -2.03/1.62\n",
            "Label: 0\n",
            "Emotion scores: [6.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0]\n",
            "Wavelet features shape: (7, 17, 17)\n",
            "Wavelet features min/max: -6.14/4.91\n",
            "Epoch: 11, Batch: 600, Loss: 1.6199, Acc: 50.23%\n",
            "Epoch: 11, Batch: 700, Loss: 1.6188, Acc: 50.31%\n",
            "Epoch: 11, Batch: 800, Loss: 1.6175, Acc: 50.49%\n",
            "\n",
            "Debug - First image:\n",
            "Image shape: (48, 48)\n",
            "Image min/max: -2.12/2.13\n",
            "Label: 7\n",
            "Emotion scores: [1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 6.0, 0.0, 0.0]\n",
            "Wavelet features shape: (7, 17, 17)\n",
            "Wavelet features min/max: -6.84/6.96\n",
            "\n",
            "Epoch 11/20:\n",
            "Training Accuracy: 50.47%\n",
            "Validation Loss: 1.5056\n",
            "Validation Accuracy: 56.62%\n",
            "Learning Rate: 0.000994\n",
            "New best model saved with accuracy: 56.62%\n",
            "Epoch: 12, Batch: 0, Loss: 1.5207, Acc: 49.81%\n",
            "Epoch: 12, Batch: 100, Loss: 1.6005, Acc: 51.65%\n",
            "Epoch: 12, Batch: 200, Loss: 1.6101, Acc: 50.55%\n",
            "Epoch: 12, Batch: 300, Loss: 1.6043, Acc: 50.99%\n",
            "Epoch: 12, Batch: 400, Loss: 1.6021, Acc: 51.13%\n",
            "\n",
            "Debug - First image:\n",
            "Image shape: (48, 48)\n",
            "Image min/max: -2.12/1.58\n",
            "Label: 0\n",
            "Emotion scores: [6.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0]\n",
            "Wavelet features shape: (7, 17, 17)\n",
            "Wavelet features min/max: -5.26/5.31\n",
            "Epoch: 12, Batch: 500, Loss: 1.5983, Acc: 51.20%\n",
            "Epoch: 12, Batch: 600, Loss: 1.6024, Acc: 50.94%\n",
            "Epoch: 12, Batch: 700, Loss: 1.6038, Acc: 50.93%\n",
            "Epoch: 12, Batch: 800, Loss: 1.6043, Acc: 50.90%\n",
            "\n",
            "Debug - First image:\n",
            "Image shape: (48, 48)\n",
            "Image min/max: -2.12/2.13\n",
            "Label: 7\n",
            "Emotion scores: [1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 6.0, 0.0, 0.0]\n",
            "Wavelet features shape: (7, 17, 17)\n",
            "Wavelet features min/max: -6.84/6.96\n",
            "\n",
            "Epoch 12/20:\n",
            "Training Accuracy: 50.96%\n",
            "Validation Loss: 1.5008\n",
            "Validation Accuracy: 56.04%\n",
            "Learning Rate: 0.000976\n",
            "Epoch: 13, Batch: 0, Loss: 1.5110, Acc: 52.80%\n",
            "Epoch: 13, Batch: 100, Loss: 1.6094, Acc: 51.25%\n",
            "Epoch: 13, Batch: 200, Loss: 1.6070, Acc: 51.38%\n",
            "Epoch: 13, Batch: 300, Loss: 1.6008, Acc: 51.44%\n",
            "Epoch: 13, Batch: 400, Loss: 1.6011, Acc: 51.30%\n",
            "Epoch: 13, Batch: 500, Loss: 1.6004, Acc: 51.33%\n",
            "Epoch: 13, Batch: 600, Loss: 1.6016, Acc: 51.17%\n",
            "Epoch: 13, Batch: 700, Loss: 1.5985, Acc: 51.44%\n",
            "Epoch: 13, Batch: 800, Loss: 1.5973, Acc: 51.53%\n",
            "\n",
            "Debug - First image:\n",
            "Image shape: (48, 48)\n",
            "Image min/max: -2.12/1.17\n",
            "Label: 0\n",
            "Emotion scores: [6.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0]\n",
            "Wavelet features shape: (7, 17, 17)\n",
            "Wavelet features min/max: -6.50/6.22\n",
            "\n",
            "Debug - First image:\n",
            "Image shape: (48, 48)\n",
            "Image min/max: -2.12/2.13\n",
            "Label: 7\n",
            "Emotion scores: [1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 6.0, 0.0, 0.0]\n",
            "Wavelet features shape: (7, 17, 17)\n",
            "Wavelet features min/max: -6.84/6.96\n",
            "\n",
            "Epoch 13/20:\n",
            "Training Accuracy: 51.61%\n",
            "Validation Loss: 1.4751\n",
            "Validation Accuracy: 58.16%\n",
            "Learning Rate: 0.000946\n",
            "New best model saved with accuracy: 58.16%\n",
            "Epoch: 14, Batch: 0, Loss: 1.3826, Acc: 59.21%\n",
            "\n",
            "Debug - First image:\n",
            "Image shape: (48, 48)\n",
            "Image min/max: -1.81/1.31\n",
            "Label: 0\n",
            "Emotion scores: [6.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0]\n",
            "Wavelet features shape: (7, 17, 17)\n",
            "Wavelet features min/max: -4.47/5.34\n",
            "Epoch: 14, Batch: 100, Loss: 1.5863, Acc: 51.14%\n",
            "Epoch: 14, Batch: 200, Loss: 1.5957, Acc: 51.29%\n",
            "Epoch: 14, Batch: 300, Loss: 1.5894, Acc: 51.56%\n",
            "Epoch: 14, Batch: 400, Loss: 1.5902, Acc: 51.74%\n",
            "Epoch: 14, Batch: 500, Loss: 1.5921, Acc: 51.62%\n",
            "Epoch: 14, Batch: 600, Loss: 1.5924, Acc: 51.65%\n",
            "Epoch: 14, Batch: 700, Loss: 1.5908, Acc: 51.64%\n",
            "Epoch: 14, Batch: 800, Loss: 1.5896, Acc: 51.58%\n",
            "\n",
            "Debug - First image:\n",
            "Image shape: (48, 48)\n",
            "Image min/max: -2.12/2.13\n",
            "Label: 7\n",
            "Emotion scores: [1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 6.0, 0.0, 0.0]\n",
            "Wavelet features shape: (7, 17, 17)\n",
            "Wavelet features min/max: -6.84/6.96\n",
            "\n",
            "Epoch 14/20:\n",
            "Training Accuracy: 51.58%\n",
            "Validation Loss: 1.5028\n",
            "Validation Accuracy: 56.29%\n",
            "Learning Rate: 0.000905\n",
            "Epoch: 15, Batch: 0, Loss: 1.4909, Acc: 49.94%\n",
            "Epoch: 15, Batch: 100, Loss: 1.5610, Acc: 53.74%\n",
            "Epoch: 15, Batch: 200, Loss: 1.5617, Acc: 53.46%\n",
            "Epoch: 15, Batch: 300, Loss: 1.5699, Acc: 53.05%\n",
            "Epoch: 15, Batch: 400, Loss: 1.5726, Acc: 53.01%\n",
            "Epoch: 15, Batch: 500, Loss: 1.5716, Acc: 53.06%\n",
            "Epoch: 15, Batch: 600, Loss: 1.5743, Acc: 52.84%\n",
            "Epoch: 15, Batch: 700, Loss: 1.5731, Acc: 52.68%\n",
            "\n",
            "Debug - First image:\n",
            "Image shape: (48, 48)\n",
            "Image min/max: -2.12/2.11\n",
            "Label: 0\n",
            "Emotion scores: [6.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0]\n",
            "Wavelet features shape: (7, 17, 17)\n",
            "Wavelet features min/max: -6.05/5.80\n"
          ]
        }
      ]
    }
  ]
}