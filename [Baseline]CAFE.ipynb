{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 클립 모델 로드\n",
    "import clip\n",
    "device = torch.device('cuda:0')\n",
    "clip_model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "from torch.nn.modules.module import Module\n",
    "from torch.nn.modules.utils import _pair\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "# 커스텀 맥스풀링\n",
    "class my_MaxPool2d(Module):\n",
    "    def __init__(self, kernel_size, stride=None, padding=0, dilation=1,\n",
    "                 return_indices=False, ceil_mode=False):\n",
    "        super(my_MaxPool2d, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride or kernel_size\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "        self.return_indices = return_indices\n",
    "        self.ceil_mode = ceil_mode\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = input.transpose(3, 1)\n",
    "        input = F.max_pool2d(input, self.kernel_size, self.stride,\n",
    "                             self.padding, self.dilation, self.ceil_mode,\n",
    "                             self.return_indices)\n",
    "        input = input.transpose(3, 1).contiguous()\n",
    "        return input\n",
    "\n",
    "    def __repr__(self):\n",
    "        kh, kw = _pair(self.kernel_size)\n",
    "        dh, dw = _pair(self.stride)\n",
    "        padh, padw = _pair(self.padding)\n",
    "        dilh, dilw = _pair(self.dilation)\n",
    "        padding_str = ', padding=(' + str(padh) + ', ' + str(padw) + ')' \\\n",
    "            if padh != 0 or padw != 0 else ''\n",
    "        dilation_str = (', dilation=(' + str(dilh) + ', ' + str(dilw) + ')'\n",
    "                        if dilh != 0 and dilw != 0 else '')\n",
    "        ceil_str = ', ceil_mode=' + str(self.ceil_mode)\n",
    "        return self.__class__.__name__ + '(' \\\n",
    "            + 'kernel_size=(' + str(kh) + ', ' + str(kw) + ')' \\\n",
    "            + ', stride=(' + str(dh) + ', ' + str(dw) + ')' \\\n",
    "            + padding_str + dilation_str + ceil_str + ')'\n",
    "\n",
    "# 커스텀 avg pooling\n",
    "class my_AvgPool2d(Module):\n",
    "    def __init__(self, kernel_size, stride=None, padding=0, ceil_mode=False,\n",
    "                 count_include_pad=True):\n",
    "        super(my_AvgPool2d, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride or kernel_size\n",
    "        self.padding = padding\n",
    "        self.ceil_mode = ceil_mode\n",
    "        self.count_include_pad = count_include_pad\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = input.transpose(3, 1)\n",
    "        input = F.avg_pool2d(input, self.kernel_size, self.stride,\n",
    "                             self.padding, self.ceil_mode, self.count_include_pad)\n",
    "        input = input.transpose(3, 1).contiguous()\n",
    "        return input\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' \\\n",
    "            + 'kernel_size=' + str(self.kernel_size) \\\n",
    "            + ', stride=' + str(self.stride) \\\n",
    "            + ', padding=' + str(self.padding) \\\n",
    "            + ', ceil_mode=' + str(self.ceil_mode) \\\n",
    "            + ', count_include_pad=' + str(self.count_include_pad) + ')'\n",
    "\n",
    "# 데이터셋 로드 (실제로는 FERPLUS)\n",
    "class RafDataset(data.Dataset):\n",
    "    def __init__(self, root_dir, phase, transform=None, apply_constraints=False):\n",
    "        self.root_dir = root_dir\n",
    "        self.phase = phase  # 'Train', 'Valid', or 'Test'\n",
    "        self.transform = transform\n",
    "\n",
    "        label_path = os.path.join(root_dir, phase, 'label.csv')\n",
    "        df = pd.read_csv(label_path, header=None)\n",
    "\n",
    "        # 컬럼 이름 지정\n",
    "        df.columns = ['filename', 'bbox'] + [f'c{i}' for i in range(10)]\n",
    "\n",
    "        # 각 예제에 대한 레이블 카운트 가져오기\n",
    "        counts = df[[f'c{i}' for i in range(10)]].astype(int)\n",
    "\n",
    "        if apply_constraints:\n",
    "            # (1) 각 감정에 대해 투표가 정확히 1표인 경우 0으로 만든다.\n",
    "            counts = counts.applymap(lambda x: 0 if x == 1 else x)\n",
    "\n",
    "            # (2) 처리 후 가장 많은 투표 수가 전체 투표의 절반을 넘지 못하면 제거\n",
    "            max_counts = counts.max(axis=1)\n",
    "            total_votes = counts.sum(axis=1)\n",
    "            valid_mask = max_counts > (total_votes / 2)\n",
    "\n",
    "            df = df[valid_mask].reset_index(drop=True)\n",
    "            counts = counts[valid_mask].reset_index(drop=True)\n",
    "\n",
    "        # 최종 레이블 결정\n",
    "        df['label'] = counts.values.argmax(axis=1)\n",
    "\n",
    "        # 레이블이 0부터 7 사이인지 확인 (8개 클래스로 변경)\n",
    "        valid_labels_mask = (df['label'] >= 0) & (df['label'] <= 7)\n",
    "        df = df[valid_labels_mask].reset_index(drop=True)\n",
    "        self.file_paths = df['filename'].values\n",
    "        self.labels = df['label'].values.astype(np.int64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.labels[idx]\n",
    "        img_path = os.path.join(self.root_dir, self.phase, self.file_paths[idx])\n",
    "\n",
    "        image = cv2.imread(img_path)\n",
    "        image = image[:, :, ::-1]  # BGR에서 RGB로 변환\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        image1 = transforms.RandomHorizontalFlip(p=1)(image)\n",
    "        return image, label, idx, image1\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        if downsample:\n",
    "            conv = nn.Conv2d(in_channels, out_channels, kernel_size=1,\n",
    "                             stride=stride, bias=False)\n",
    "            bn = nn.BatchNorm2d(out_channels)\n",
    "            downsample = nn.Sequential(conv, bn)\n",
    "        else:\n",
    "            downsample = None\n",
    "\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        i = x\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            i = self.downsample(i)\n",
    "\n",
    "        x += i\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, n_blocks, channels, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = channels[0]\n",
    "\n",
    "        assert len(n_blocks) == len(channels) == 4\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self.get_resnet_layer(block, n_blocks[0], channels[0])\n",
    "        self.layer2 = self.get_resnet_layer(block, n_blocks[1], channels[1], stride=2)\n",
    "        self.layer3 = self.get_resnet_layer(block, n_blocks[2], channels[2], stride=2)\n",
    "        self.layer4 = self.get_resnet_layer(block, n_blocks[3], channels[3], stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(self.in_channels, output_dim)\n",
    "\n",
    "    def get_resnet_layer(self, block=BasicBlock, n_blocks=2, channels=64, stride=1):\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        if self.in_channels != block.expansion * channels:\n",
    "            downsample = True\n",
    "        else:\n",
    "            downsample = False\n",
    "\n",
    "        layers.append(block(self.in_channels, channels, stride, downsample))\n",
    "\n",
    "        for i in range(1, n_blocks):\n",
    "            layers.append(block(block.expansion * channels, channels))\n",
    "\n",
    "        self.in_channels = block.expansion * channels\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        h = x.view(x.shape[0], -1)\n",
    "        x = self.fc(h)\n",
    "\n",
    "        return x, h\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "def Mask(nb_batch, num_classes=8):  # num_classes 변경\n",
    "    total_channels = 512\n",
    "    channels_per_class = total_channels // num_classes\n",
    "    remainder = total_channels % num_classes\n",
    "\n",
    "    class_channel_counts = [channels_per_class] * num_classes\n",
    "    for i in range(remainder):\n",
    "        class_channel_counts[i] += 1\n",
    "\n",
    "    bar = []\n",
    "    for _ in range(nb_batch):\n",
    "        batch_bar = [0] * total_channels\n",
    "\n",
    "        active_channels = []\n",
    "        for count in class_channel_counts:\n",
    "            indices = random.sample(range(total_channels), count)\n",
    "            active_channels.extend(indices)\n",
    "\n",
    "        for idx in active_channels:\n",
    "            batch_bar[idx] = 1\n",
    "\n",
    "        bar.append(batch_bar)\n",
    "\n",
    "    bar = np.array(bar).astype(\"float32\")\n",
    "    bar = bar.reshape(nb_batch, total_channels, 1, 1)\n",
    "    bar = torch.from_numpy(bar)\n",
    "    bar = bar.to(device)\n",
    "    return bar\n",
    "\n",
    "def supervisor(x, targets, cnum):\n",
    "    branch = x\n",
    "    branch = branch.reshape(branch.size(0), branch.size(1), 1, 1)\n",
    "    branch = my_MaxPool2d(kernel_size=(1, cnum), stride=(1, cnum))(branch)\n",
    "    branch = branch.reshape(branch.size(0), branch.size(1), branch.size(2) * branch.size(3))\n",
    "    loss_2 = 1.0 - 1.0 * torch.mean(torch.sum(branch, 2)) / cnum\n",
    "\n",
    "    mask = Mask(x.size(0), num_classes=8)  # num_classes 변경\n",
    "    branch_1 = x.reshape(x.size(0), x.size(1), 1, 1) * mask\n",
    "    branch_1 = my_MaxPool2d(kernel_size=(1, cnum), stride=(1, cnum))(branch_1)\n",
    "    branch_1 = branch_1.view(branch_1.size(0), -1)\n",
    "    loss_1 = nn.CrossEntropyLoss()(branch_1, targets)\n",
    "    return [loss_1, loss_2]\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, pretrained=True, num_classes=8, drop_rate=0):  # num_classes 변경\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        res18 = ResNet(block=BasicBlock, n_blocks=[2, 2, 2, 2],\n",
    "                       channels=[64, 128, 256, 512], output_dim=1000)\n",
    "\n",
    "        try:\n",
    "            msceleb_model = torch.load('../.././resnet18_msceleb.pth')\n",
    "            state_dict = msceleb_model['state_dict']\n",
    "            res18.load_state_dict(state_dict, strict=False)\n",
    "            print(\"---RESNET MSCELEB LOADED--\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"Pre-trained model not found. Using torchvision's pre-trained model.\")\n",
    "            res18 = models.resnet18(pretrained=True)\n",
    "\n",
    "        self.drop_rate = drop_rate\n",
    "        self.features = nn.Sequential(*list(res18.children())[:-2])  # 마지막 두 레이어 제거\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # Global Average Pooling 추가\n",
    "\n",
    "        fc_in_dim = 512\n",
    "        self.fc = nn.Linear(fc_in_dim, num_classes)  # num_classes=8\n",
    "\n",
    "        self.parm = {}\n",
    "        for name, parameters in self.fc.named_parameters():\n",
    "            print(name, ':', parameters.size())\n",
    "            self.parm[name] = parameters\n",
    "\n",
    "    def forward(self, x, clip_model, targets, phase='train'):\n",
    "        with torch.no_grad():\n",
    "            image_features = clip_model.encode_image(x)  # (batch, 512)\n",
    "\n",
    "        x = self.features(x)  # (batch, 512, 7, 7)\n",
    "        x = self.avgpool(x)   # (batch, 512, 1, 1)\n",
    "        x = x.view(x.size(0), -1)  # (batch, 512)\n",
    "\n",
    "        if x.size(1) != image_features.size(1):\n",
    "            x = nn.Linear(x.size(1), image_features.size(1)).to(x.device)(x)\n",
    "\n",
    "        if phase == 'train':\n",
    "            MC_loss = supervisor(image_features * torch.sigmoid(x), targets, cnum=64)  # cnum=64\n",
    "\n",
    "        x = image_features * torch.sigmoid(x)  # (batch, 512)\n",
    "        out = self.fc(x)  # (batch, num_classes=8)\n",
    "\n",
    "        if phase == 'train':\n",
    "            return out, MC_loss\n",
    "        else:\n",
    "            return out, out\n",
    "\n",
    "def add_g(image_array, mean=0.0, var=30):\n",
    "    std = var ** 0.5\n",
    "    image_add = image_array + np.random.normal(mean, std, image_array.shape)\n",
    "    image_add = np.clip(image_add, 0, 255).astype(np.uint8)\n",
    "    return image_add\n",
    "\n",
    "def flip_image(image_array):\n",
    "    return cv2.flip(image_array, 1)\n",
    "\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.raf_path = '/home/work/dhkim/fer/FERPlus/data'  \n",
    "        self.resnet50_path = '../../resnet50_ft_weight.pkl'\n",
    "        self.label_path = 'list_patition_label.txt'\n",
    "        self.workers = 4\n",
    "        self.batch_size = 32\n",
    "        self.w = 7\n",
    "        self.h = 7\n",
    "        self.gpu = 0\n",
    "        self.lam = 5\n",
    "        self.epochs = 20\n",
    "\n",
    "args = Args()\n",
    "\n",
    "def train(args, model, train_loader, optimizer, scheduler, device):\n",
    "    running_loss = 0.0\n",
    "    iter_cnt = 0\n",
    "    correct_sum = 0\n",
    "\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    for batch_i, (imgs1, labels, indexes, imgs2) in enumerate(train_loader):\n",
    "        imgs1 = imgs1.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        output, MC_loss = model(imgs1, clip_model, labels, phase='train')\n",
    "\n",
    "        loss1 = nn.CrossEntropyLoss()(output, labels)\n",
    "        loss = loss1 + 5 * MC_loss[1] + 1.5 * MC_loss[0]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        iter_cnt += 1\n",
    "        _, predicts = torch.max(output, 1)\n",
    "        correct_num = torch.eq(predicts, labels).sum()\n",
    "        correct_sum += correct_num\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "    running_loss = running_loss / iter_cnt\n",
    "    acc = correct_sum.float() / float(len(train_loader.dataset))\n",
    "    return acc, running_loss\n",
    "\n",
    "def test(model, test_loader, device):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        iter_cnt = 0\n",
    "        correct_sum = 0\n",
    "        data_num = 0\n",
    "\n",
    "        for batch_i, (imgs1, labels, indexes, imgs2) in enumerate(test_loader):\n",
    "            imgs1 = imgs1.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs, _ = model(imgs1, clip_model, labels, phase='Test')\n",
    "\n",
    "            loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "\n",
    "            iter_cnt += 1\n",
    "            _, predicts = torch.max(outputs, 1)\n",
    "\n",
    "            correct_num = torch.eq(predicts, labels).sum()\n",
    "            correct_sum += correct_num\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            data_num += outputs.size(0)\n",
    "\n",
    "        running_loss = running_loss / iter_cnt\n",
    "        test_acc = correct_sum.float() / float(data_num)\n",
    "\n",
    "    return test_acc, running_loss\n",
    "\n",
    "def main():\n",
    "    setup_seed(3407)\n",
    "\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomErasing(scale=(0.02, 0.25))\n",
    "    ])\n",
    "\n",
    "    eval_transforms = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    train_dataset = RafDataset(root_dir=args.raf_path, phase='Train', transform=train_transforms, apply_constraints=True)\n",
    "    test_dataset = RafDataset(args.raf_path, phase='Test', transform=eval_transforms, apply_constraints=True)\n",
    "    val_dataset = RafDataset(args.raf_path, phase='Valid', transform=eval_transforms, apply_constraints=True)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                               batch_size=args.batch_size,\n",
    "                                               shuffle=True,\n",
    "                                               num_workers=args.workers,\n",
    "                                               pin_memory=False)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=args.batch_size,\n",
    "                                             shuffle=False,\n",
    "                                             num_workers=args.workers,\n",
    "                                             pin_memory=False)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.batch_size,\n",
    "                                              shuffle=False,\n",
    "                                              num_workers=args.workers,\n",
    "                                              pin_memory=False)\n",
    "\n",
    "    model = Model(num_classes=8)  # num_classes=8로 변경\n",
    "\n",
    "    device = torch.device('cuda:{}'.format(args.gpu))\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0002, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "    best_val_acc = 0.0  # 최고 Validation Accuracy 기록\n",
    "    best_model_path = \"best_model.pth\"\n",
    "\n",
    "    for i in range(1, args.epochs + 1):\n",
    "        train_acc, train_loss = train(args, model, train_loader, optimizer, scheduler, device)\n",
    "        val_acc, val_loss = test(model, val_loader, device)\n",
    "        print(f\"Epoch: {i}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Validation Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}\")\n",
    "\n",
    "        # Validation Accuracy가 최고일 때 모델 저장\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save({'model_state_dict': model.state_dict()}, best_model_path)\n",
    "            print(f\"[INFO] New Best Model Saved with Validation Accuracy: {best_val_acc:.4f}\")\n",
    "\n",
    "        with open('results.txt', 'a') as f:\n",
    "            f.write(f\"Epoch: {i}, Validation Accuracy: {val_acc:.4f}, Validation Loss: {val_loss:.4f}\\n\")\n",
    "\n",
    "    print(\"\\n[Final Evaluation on Test Set with Best Model]\")\n",
    "    # 최적 모델 로드\n",
    "    checkpoint = torch.load(best_model_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    test_acc, test_loss = test(model, test_loader, device)\n",
    "    print(f\"Best Validation Accuracy: {best_val_acc:.4f}\")\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    with open('results.txt', 'a') as f:\n",
    "        f.write(f\"Best Validation Accuracy: {best_val_acc:.4f}\\n\")\n",
    "        f.write(f\"Final Test Accuracy: {test_acc:.4f}, Test Loss: {test_loss:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-trained model not found. Using torchvision's pre-trained model.\n",
      "weight : torch.Size([8, 512])\n",
      "bias : torch.Size([8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/work/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 8.6520, Train Acc: 0.6887, Validation Loss: 0.6935, Validation Acc: 0.8132\n",
      "[INFO] New Best Model Saved with Validation Accuracy: 0.8132\n",
      "Epoch: 2, Train Loss: 8.1380, Train Acc: 0.8074, Validation Loss: 0.5382, Validation Acc: 0.8402\n",
      "[INFO] New Best Model Saved with Validation Accuracy: 0.8402\n",
      "Epoch: 3, Train Loss: 7.9757, Train Acc: 0.8341, Validation Loss: 0.4763, Validation Acc: 0.8499\n",
      "[INFO] New Best Model Saved with Validation Accuracy: 0.8499\n",
      "Epoch: 4, Train Loss: 7.8919, Train Acc: 0.8510, Validation Loss: 0.4353, Validation Acc: 0.8662\n",
      "[INFO] New Best Model Saved with Validation Accuracy: 0.8662\n",
      "Epoch: 5, Train Loss: 7.8323, Train Acc: 0.8652, Validation Loss: 0.4181, Validation Acc: 0.8709\n",
      "[INFO] New Best Model Saved with Validation Accuracy: 0.8709\n",
      "Epoch: 6, Train Loss: 7.7724, Train Acc: 0.8805, Validation Loss: 0.3916, Validation Acc: 0.8768\n",
      "[INFO] New Best Model Saved with Validation Accuracy: 0.8768\n",
      "Epoch: 7, Train Loss: 7.7253, Train Acc: 0.8900, Validation Loss: 0.4131, Validation Acc: 0.8612\n",
      "Epoch: 8, Train Loss: 7.6853, Train Acc: 0.9004, Validation Loss: 0.3858, Validation Acc: 0.8756\n",
      "Epoch: 9, Train Loss: 7.6556, Train Acc: 0.9101, Validation Loss: 0.3860, Validation Acc: 0.8778\n",
      "[INFO] New Best Model Saved with Validation Accuracy: 0.8778\n",
      "Epoch: 10, Train Loss: 7.6117, Train Acc: 0.9221, Validation Loss: 0.3764, Validation Acc: 0.8825\n",
      "[INFO] New Best Model Saved with Validation Accuracy: 0.8825\n",
      "Epoch: 11, Train Loss: 7.5763, Train Acc: 0.9300, Validation Loss: 0.3821, Validation Acc: 0.8815\n",
      "Epoch: 12, Train Loss: 7.5466, Train Acc: 0.9366, Validation Loss: 0.3799, Validation Acc: 0.8806\n",
      "Epoch: 13, Train Loss: 7.5253, Train Acc: 0.9434, Validation Loss: 0.3744, Validation Acc: 0.8840\n",
      "[INFO] New Best Model Saved with Validation Accuracy: 0.8840\n",
      "Epoch: 14, Train Loss: 7.5048, Train Acc: 0.9490, Validation Loss: 0.3840, Validation Acc: 0.8784\n",
      "Epoch: 15, Train Loss: 7.4925, Train Acc: 0.9526, Validation Loss: 0.3903, Validation Acc: 0.8759\n",
      "Epoch: 16, Train Loss: 7.4780, Train Acc: 0.9557, Validation Loss: 0.3808, Validation Acc: 0.8825\n",
      "Epoch: 17, Train Loss: 7.4673, Train Acc: 0.9583, Validation Loss: 0.3869, Validation Acc: 0.8797\n",
      "Epoch: 18, Train Loss: 7.4527, Train Acc: 0.9614, Validation Loss: 0.3837, Validation Acc: 0.8787\n",
      "Epoch: 19, Train Loss: 7.4457, Train Acc: 0.9626, Validation Loss: 0.3896, Validation Acc: 0.8834\n",
      "Epoch: 20, Train Loss: 7.4443, Train Acc: 0.9645, Validation Loss: 0.3865, Validation Acc: 0.8881\n",
      "[INFO] New Best Model Saved with Validation Accuracy: 0.8881\n",
      "\n",
      "[Final Evaluation on Test Set with Best Model]\n",
      "Best Validation Accuracy: 0.8881\n",
      "Test Loss: 0.4136, Test Accuracy: 0.8757\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.2 (NGC 23.11/Python 3.10) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
